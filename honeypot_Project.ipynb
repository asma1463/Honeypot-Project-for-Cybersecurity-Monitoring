{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPQfIe4vsYpK",
        "outputId": "c0b23b2a-412e-4541-c46d-fd7c09f422be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.2)\n",
            "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m1.0/1.9 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m\u001b[91m笊ｸ\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p70YXjQSsan3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179f3d07-dafd-4e45-9368-5943af35193c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pywavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from pywavelets) (2.0.2)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pywavelets\n",
            "Successfully installed pywavelets-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pywavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aWj6WWesYg9",
        "outputId": "977c4261-5e4d-42a5-af3e-25c1bcbf9198"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pywavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from pywavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pywavelets\n",
            "Successfully installed pywavelets-1.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pywavelets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ea3ofoa4xUca",
        "outputId": "41c05d75-6c8d-4cbe-9c14-092b957682d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.1.0)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "!pip install pytesseract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NbJvWlL4EWkw",
        "outputId": "2dcf368c-8504-4684-9f45-1497943d63c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting faker\n",
            "  Downloading faker-37.1.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: tzdata in /usr/local/lib/python3.11/dist-packages (from faker) (2025.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Downloading faker-37.1.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faker\n",
            "Successfully installed faker-37.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install faker tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-0YQPXBRszp",
        "outputId": "529cd8ad-1c0b-4857-f411-3bb5f74f2311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting exifread\n",
            "  Downloading ExifRead-3.0.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Downloading ExifRead-3.0.0-py3-none-any.whl (40 kB)\n",
            "\u001b[?25l   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m0.0/40.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m40.4/40.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: exifread\n",
            "Successfully installed exifread-3.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install exifread"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6mH0_Rpbpcp",
        "outputId": "6eadae7f-fe87-4e9d-fce8-4d660c49c1d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61DV0L4pER52",
        "outputId": "e5248966-8449-4e9a-abb7-0a03b15c2112"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy<2.0.0,>=1.24.0 (from facenet-pytorch)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch)\n",
            "  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch)\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch)\n",
            "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
            "Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m72.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m34.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m827.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))': /packages/86/94/eb540db023ce1d162e7bea9f8f5aa781d57c65aed513c33ee9a5123ead4d/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl\u001b[0m\u001b[33m\n",
            "\u001b[0mDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[91m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m\u001b[90m笊ｺ\u001b[0m\u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏―u001b[0m \u001b[32m77.0/167.9 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: THESE PACKAGES DO NOT MATCH THE HASHES FROM THE REQUIREMENTS FILE. If you have updated the package versions, please update the hashes. Otherwise, examine the package contents carefully; someone may have tampered with them.\n",
            "    unknown package:\n",
            "        Expected sha256 da58a152bddb62cafa9a857dd2bc1f886dbf9f9c90a2b5da82157cd2b34392b0\n",
            "             Got        026946fb8e0758ff70a4a8023d4157d6b902e452615c496677171c6b72bacf36\n",
            "\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install facenet-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-hw1F_4ER2a",
        "outputId": "344cbf75-7c79-4914-9bdb-fc0768cdb291"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deepface\n",
            "  Downloading deepface-0.0.93-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: requests>=2.27.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.2.2)\n",
            "Requirement already satisfied: gdown>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from deepface) (5.2.0)\n",
            "Requirement already satisfied: tqdm>=4.30.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.67.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (11.1.0)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.11/dist-packages (from deepface) (4.11.0.86)\n",
            "Requirement already satisfied: tensorflow>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (2.18.0)\n",
            "Requirement already satisfied: keras>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.8.0)\n",
            "Requirement already satisfied: Flask>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from deepface) (3.1.0)\n",
            "Collecting flask-cors>=4.0.1 (from deepface)\n",
            "  Downloading flask_cors-5.0.1-py3-none-any.whl.metadata (961 bytes)\n",
            "Collecting mtcnn>=0.1.0 (from deepface)\n",
            "  Downloading mtcnn-1.0.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting retina-face>=0.0.1 (from deepface)\n",
            "  Downloading retina_face-0.0.17-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting fire>=0.4.0 (from deepface)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gunicorn>=20.1.0 (from deepface)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire>=0.4.0->deepface) (3.0.1)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=1.1.2->deepface) (1.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown>=3.10.1->deepface) (3.18.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gunicorn>=20.1.0->deepface) (24.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (1.4.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (3.13.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.15.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.11/dist-packages (from keras>=2.2.0->deepface) (0.4.1)\n",
            "Requirement already satisfied: joblib>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from mtcnn>=0.1.0->deepface) (1.4.2)\n",
            "Collecting lz4>=4.3.3 (from mtcnn>=0.1.0->deepface)\n",
            "  Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.23.4->deepface) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.27.1->deepface) (2025.1.31)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow>=1.9.0->deepface) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow>=1.9.0->deepface) (0.45.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=1.1.2->deepface) (3.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow>=1.9.0->deepface) (0.7.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown>=3.10.1->deepface) (2.6)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown>=3.10.1->deepface) (1.7.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=2.2.0->deepface) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=2.2.0->deepface) (0.1.2)\n",
            "Downloading deepface-0.0.93-py3-none-any.whl (108 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m108.6/108.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-5.0.1-py3-none-any.whl (11 kB)\n",
            "Downloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mtcnn-1.0.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retina_face-0.0.17-py3-none-any.whl (25 kB)\n",
            "Downloading lz4-4.4.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=ae967d1858f178a446b2e9411a5db6cbfb16b4dadc8b6d4e1d683c3dbd5bbe66\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: lz4, gunicorn, fire, mtcnn, flask-cors, retina-face, deepface\n",
            "Successfully installed deepface-0.0.93 fire-0.7.0 flask-cors-5.0.1 gunicorn-23.0.0 lz4-4.4.4 mtcnn-1.0.0 retina-face-0.0.17\n"
          ]
        }
      ],
      "source": [
        "!pip install deepface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FF9dttxgYzMA",
        "outputId": "8737614f-e9ae-48a6-cfa6-1f5551e4b00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "笨 Generated Mixed Users and Transactions with Balance Tracking\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py:82: UserWarning: The model does not have any trainable weights.\n",
            "  warnings.warn(\"The model does not have any trainable weights.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 | D Loss: 0.6852 | G Loss: 0.6967\n",
            "Epoch 100 | D Loss: 5.2624 | G Loss: 0.0846\n",
            "Epoch 200 | D Loss: 6.3534 | G Loss: 0.0425\n",
            "Epoch 300 | D Loss: 6.7526 | G Loss: 0.0284\n",
            "Epoch 400 | D Loss: 6.9992 | G Loss: 0.0213\n",
            "Epoch 500 | D Loss: 7.1862 | G Loss: 0.0171\n",
            "Epoch 600 | D Loss: 7.3268 | G Loss: 0.0142\n",
            "Epoch 700 | D Loss: 7.4534 | G Loss: 0.0122\n",
            "Epoch 800 | D Loss: 7.5728 | G Loss: 0.0107\n",
            "Epoch 900 | D Loss: 7.6872 | G Loss: 0.0095\n",
            "笨 Generated AI-Based Synthetic Transactions:\n",
            "[[ 59.99975   53.617718  68.70237   29.080914  61.06513 ]\n",
            " [ 79.85269   71.07508   90.82258   38.54982   80.97698 ]\n",
            " [101.63056   90.8926   115.81887   49.481228 103.56958 ]\n",
            " [109.83095   98.44951  124.93566   53.21177  111.249664]\n",
            " [ 71.06454   63.83014   81.39421   34.376656  72.00549 ]\n",
            " [ 57.99691   51.872044  66.13137   28.1352    59.04084 ]\n",
            " [ 72.09931   64.84305   82.45239   35.22082   73.21309 ]\n",
            " [ 99.06112   88.81574  113.28467   48.124836 100.38305 ]\n",
            " [ 59.824463  53.56059   68.01053   28.951067  60.779488]\n",
            " [ 87.338646  78.142494  99.56592   42.29767   88.31351 ]]\n",
            "沒 Data saved to 'mixed_users.csv' and 'mixed_transactions.csv'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "import faker\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential, Model, Input\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "fake = faker.Faker()\n",
        "\n",
        "def generate_real_users(n=500):\n",
        "    return pd.DataFrame([{\n",
        "        \"user_id\": fake.uuid4(),\n",
        "        \"name\": fake.name(),\n",
        "        \"address\": fake.address().replace(\"\\n\", \", \"),\n",
        "        \"bank_account\": fake.iban(),\n",
        "        \"credit_card\": fake.credit_card_number(),\n",
        "        \"crypto_wallet\": fake.cryptocurrency()[1],\n",
        "        \"credit_score\": random.randint(600, 850),\n",
        "        \"balance\": round(random.uniform(1000, 10000), 2)\n",
        "    } for _ in range(n)])\n",
        "\n",
        "def generate_fake_users(n=500):\n",
        "    return pd.DataFrame([{\n",
        "        \"user_id\": fake.uuid4(),\n",
        "        \"name\": fake.name(),\n",
        "        \"address\": fake.address().replace(\"\\n\", \", \"),\n",
        "        \"bank_account\": \"FAKE\" + str(random.randint(100000, 999999)),\n",
        "        \"credit_card\": \"FAKE\" + str(random.randint(100000, 999999)),\n",
        "        \"crypto_wallet\": \"FAKE_WALLET\",\n",
        "        \"credit_score\": random.randint(300, 599),\n",
        "        \"balance\": round(random.uniform(100, 1000), 2)\n",
        "    } for _ in range(n)])\n",
        "\n",
        "def generate_transactions(users_df, n=5000, fraud_ratio=0.2):\n",
        "    users_df = users_df.copy()\n",
        "    user_balances = users_df.set_index(\"user_id\")[\"balance\"].to_dict()\n",
        "\n",
        "    tx_types = ['deposit', 'withdrawal', 'crypto_transfer', 'purchase']\n",
        "    transactions = []\n",
        "\n",
        "    for _ in range(n):\n",
        "        user_id = random.choice(users_df['user_id'].tolist())\n",
        "        tx_type = random.choice(tx_types)\n",
        "        amount = round(random.uniform(5, 5000), 2)\n",
        "        fraudulent = int(random.random() < fraud_ratio)\n",
        "\n",
        "        balance = user_balances.get(user_id, 0)\n",
        "        if tx_type in ['withdrawal', 'purchase', 'crypto_transfer']:\n",
        "            if balance >= amount:\n",
        "                user_balances[user_id] -= amount\n",
        "            else:\n",
        "                continue\n",
        "        elif tx_type == 'deposit':\n",
        "            user_balances[user_id] += amount\n",
        "\n",
        "        transactions.append({\n",
        "            \"transaction_id\": fake.uuid4(),\n",
        "            \"user_id\": user_id,\n",
        "            \"amount\": amount,\n",
        "            \"transaction_type\": tx_type,\n",
        "            \"timestamp\": fake.date_time_this_decade(),\n",
        "            \"fraudulent\": fraudulent\n",
        "        })\n",
        "\n",
        "    users_df[\"balance\"] = users_df[\"user_id\"].map(user_balances)\n",
        "    return pd.DataFrame(transactions), users_df\n",
        "\n",
        "def preprocess_transactions(transactions_df):\n",
        "    encoder = OneHotEncoder(sparse_output=False)\n",
        "    transaction_types_encoded = encoder.fit_transform(transactions_df[['transaction_type']])\n",
        "    X_train = np.hstack((transactions_df[['amount']].values, transaction_types_encoded))\n",
        "    X_train = (X_train - X_train.mean(axis=0)) / X_train.std(axis=0)\n",
        "    return X_train, encoder\n",
        "\n",
        "def build_generator(noise_dim, output_dim):\n",
        "    return Sequential([\n",
        "        Input(shape=(noise_dim,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(output_dim, activation='linear')\n",
        "    ])\n",
        "\n",
        "def build_discriminator(input_dim):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_dim,)),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "def train_gan(transactions_df, epochs=1000):\n",
        "    X_train, encoder = preprocess_transactions(transactions_df)\n",
        "    noise_dim = 10\n",
        "\n",
        "    generator = build_generator(noise_dim, X_train.shape[1])\n",
        "    discriminator = build_discriminator(X_train.shape[1])\n",
        "\n",
        "    discriminator.trainable = False\n",
        "    noise_input = Input(shape=(noise_dim,))\n",
        "    generated_sample = generator(noise_input)\n",
        "    validity = discriminator(generated_sample)\n",
        "\n",
        "    gan = Model(noise_input, validity)\n",
        "    gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "    batch_size = 64\n",
        "    for epoch in range(epochs):\n",
        "        idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
        "        real = X_train[idx]\n",
        "        noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
        "        fake = generator.predict(noise, verbose=0)\n",
        "\n",
        "        d_loss_real = discriminator.train_on_batch(real, np.ones((batch_size, 1)))\n",
        "        d_loss_fake = discriminator.train_on_batch(fake, np.zeros((batch_size, 1)))\n",
        "        gan_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch} | D Loss: {np.mean([d_loss_real[0], d_loss_fake[0]]):.4f} | G Loss: {gan_loss:.4f}\")\n",
        "\n",
        "    return generator, encoder\n",
        "\n",
        "real_users_df = generate_real_users()\n",
        "fake_users_df = generate_fake_users()\n",
        "users_df = pd.concat([real_users_df, fake_users_df], ignore_index=True)\n",
        "transactions_df, users_df = generate_transactions(users_df)\n",
        "\n",
        "print(\"笨 Generated Mixed Users and Transactions with Balance Tracking\")\n",
        "\n",
        "generator_model, encoder = train_gan(transactions_df, epochs=1000)\n",
        "\n",
        "noise_input = np.random.normal(0, 1, (10, 10))\n",
        "generated_transactions = generator_model.predict(noise_input, verbose=0)\n",
        "\n",
        "print(\"笨 Generated AI-Based Synthetic Transactions:\")\n",
        "print(generated_transactions)\n",
        "\n",
        "users_df.to_csv(\"mixed_users.csv\", index=False)\n",
        "transactions_df.to_csv(\"mixed_transactions.csv\", index=False)\n",
        "print(\"沒 Data saved to 'mixed_users.csv' and 'mixed_transactions.csv'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ht1TEqGYzHH",
        "outputId": "e1cb4557-eeb1-4d61-817a-bcfe5e3b6f40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "汨 Welcome to SecureBank Assistant. Enter your User ID to begin. Type 'exit' to quit.\n",
            "洫 You: hello\n",
            "洟 Bot: 汨､ Please enter your User ID from `mixed_users.csv`.\n",
            "洟 Bot: 笶 Invalid User ID. Please try again.\n",
            "洫 You: b02620cb-aa84-4ad1-9cc6-288e54ad721d\n",
            "洟 Bot: 汨､ Please enter your User ID from `mixed_users.csv`.\n",
            "洟 Bot: 汨 Hello Jeremy Reyes! How can I help you today?\n",
            "汳ｼ Account Info: Bank - GB66VDCE37498088037577, Credit Card - 5163829320333051\n",
            "汳ｳ Crypto Wallet: Decred | Credit Score: 750\n",
            "汳ｰ Balance: $1542.01\n",
            "沒 Recent Transactions: 5 found.\n",
            "洫 You: show me my last transactions\n",
            "洟 Bot: Here are your recent transactions:1. **Withdrawal**   - **Amount:** $2505.76   - **Transaction ID:** 6a6c1dcf-48d0-4b99-bee4-fc80a73ebd59   - **Date:** May 9, 20222. **Deposit**   - **Amount:** $2865.53   - **Transaction ID:** a9ef3376-b1ba-4106-8be3-f9ab676846ff   - **Date:** November 15, 20213. **Crypto Transfer**   - **Amount:** $805.69   - **Transaction ID:** 65e0ff71-51b9-4547-a8e2-b8582dc95ab5   - **Date:** May 28, 2020If you have any further questions or need assistance with anything else, feel free to ask!\n",
            "洫 You: i want to deposit some money\n",
            "洟 Bot: Hello Jeremy,Thank you for reaching out! I'd be happy to assist you with your deposit. Please let me know the amount you'd like to deposit and how you would like to proceed with the transaction (e.g., through a bank transfer, check, or another method).If you have any questions or need further assistance, feel free to ask!\n",
            "洫 You: i want to deposit 100 dollars\n",
            "洟 Bot: Hello Jeremy,Thank you for reaching out! To proceed with your request to deposit $100, please let me know if you would like to make the deposit through your bank account or if you prefer using your crypto wallet. If you choose the bank account option, you can initiate the deposit through your online banking portal or app. If you have any questions or need assistance with the process, feel free to ask!Best regards,SecureBank Assistant\n",
            "洫 You: using my bank account\n",
            "洟 Bot: Hello Jeremy,Thank you for reaching out. How can I assist you with your bank account today? If you need help with transactions, account balance inquiries, or anything else related to your account, please let me know! Best regards,  SecureBank Assistant\n",
            "洫 You: exit\n",
            "汨 Goodbye!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import re\n",
        "import random\n",
        "import time\n",
        "\n",
        "users_df = pd.read_csv('mixed_users.csv')\n",
        "transactions_df = pd.read_csv('mixed_transactions.csv')\n",
        "\n",
        "scam_keywords = [\n",
        "    \"urgent\", \"transfer now\", \"act fast\", \"verify\", \"account suspended\", \"click link\",\n",
        "    \"send crypto\", \"gift card\", \"security alert\", \"reset account\", \"foreign bank\", \"western union\"\n",
        "]\n",
        "\n",
        "GPT_API_KEY = \"8f7ca2fcf7360f5c9bc544c33637bd35\"\n",
        "GPT_API_URL = \"http://195.179.229.119/gpt/api.php\"\n",
        "\n",
        "def get_gpt_reply(prompt):\n",
        "    params = {\n",
        "        \"prompt\": prompt,\n",
        "        \"api_key\": GPT_API_KEY,\n",
        "        \"model\": \"gpt-3.5-turbo\"\n",
        "    }\n",
        "    try:\n",
        "        res = requests.get(GPT_API_URL, params=params)\n",
        "        data = res.json()\n",
        "        return data.get(\"content\", \"笞ｸ No response text found.\")\n",
        "    except Exception as e:\n",
        "        return f\"笞ｸ GPT API Error: {e}\"\n",
        "\n",
        "def is_scam(text):\n",
        "    lower_text = text.lower()\n",
        "    return any(keyword in lower_text for keyword in scam_keywords)\n",
        "\n",
        "def get_user_info(user_id):\n",
        "    user_row = users_df[users_df['user_id'] == user_id]\n",
        "    if user_row.empty:\n",
        "        return None\n",
        "    return user_row.iloc[0]\n",
        "\n",
        "def get_user_transactions(user_id):\n",
        "    return transactions_df[transactions_df['user_id'] == user_id].sort_values(by=\"timestamp\", ascending=False)\n",
        "\n",
        "def log_scam_report(user_data, conversation):\n",
        "    with open(\"scam_reports.txt\", \"a\") as f:\n",
        "        f.write(\"\\n====== SCAM DETECTED ======\\n\")\n",
        "        f.write(f\"User: {user_data['name']} | ID: {user_data['user_id']}\\n\")\n",
        "        f.write(f\"Bank: {user_data['bank_account']}, Crypto: {user_data['crypto_wallet']}\\n\")\n",
        "        f.write(f\"Credit Score: {user_data['credit_score']}, Balance: ${user_data['balance']:.2f}\\n\")\n",
        "        f.write(\"Conversation:\\n\")\n",
        "        for line in conversation:\n",
        "            f.write(f\"{line}\\n\")\n",
        "        f.write(\"====== END ======\\n\")\n",
        "\n",
        "def start_chatbot():\n",
        "    print(\"汨 Welcome to SecureBank Assistant. Enter your User ID to begin. Type 'exit' to quit.\")\n",
        "    authenticated = False\n",
        "    user_data = None\n",
        "\n",
        "    scam_mode = False\n",
        "    stall_count = 0\n",
        "    chat_log = []\n",
        "\n",
        "    bait_prompts = [\n",
        "        \"Hmm, that's interesting. Can you provide more details?\",\n",
        "        \"Okay, before we proceed, can you verify your location?\",\n",
        "        \"Sure! Please hold while I verify your identity...\",\n",
        "        \"Let me check our servers, one sec...\",\n",
        "        \"Oh, I need some extra confirmation before we continue.\",\n",
        "        \"Almost done! Can you confirm your email address?\"\n",
        "    ]\n",
        "\n",
        "    while True:\n",
        "        user_input = input(\"洫 You: \").strip()\n",
        "        chat_log.append(f\"User: {user_input}\")\n",
        "\n",
        "        if user_input.lower() == \"exit\":\n",
        "            print(\"汨 Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not authenticated:\n",
        "            print(\"洟 Bot: 汨､ Please enter your User ID from `mixed_users.csv`.\")\n",
        "            user_data = get_user_info(user_input)\n",
        "            if user_data is not None:\n",
        "                authenticated = True\n",
        "                print(f\"洟 Bot: 汨 Hello {user_data['name']}! How can I help you today?\")\n",
        "                print(f\"汳ｼ Account Info: Bank - {user_data['bank_account']}, Credit Card - {user_data['credit_card']}\")\n",
        "                print(f\"汳ｳ Crypto Wallet: {user_data['crypto_wallet']} | Credit Score: {user_data['credit_score']}\")\n",
        "                print(f\"汳ｰ Balance: ${user_data['balance']:.2f}\")\n",
        "                user_txns = get_user_transactions(user_input)\n",
        "                print(f\"沒 Recent Transactions: {len(user_txns)} found.\")\n",
        "            else:\n",
        "                print(\"洟 Bot: 笶 Invalid User ID. Please try again.\")\n",
        "            continue\n",
        "\n",
        "        if \"balance\" in user_input.lower():\n",
        "            print(f\"洟 Bot: 沛ｦ Your current balance is: ${user_data['balance']:.2f}\")\n",
        "            chat_log.append(f\"Bot: Balance: ${user_data['balance']:.2f}\")\n",
        "            continue\n",
        "\n",
        "        if not scam_mode and is_scam(user_input):\n",
        "            scam_mode = True\n",
        "            print(\"洟 Bot: 泅ｨ Suspicious activity detected. Please wait while we verify.\")\n",
        "            chat_log.append(\"Bot: 泅ｨ Scam suspicion triggered.\")\n",
        "            continue\n",
        "\n",
        "        if scam_mode:\n",
        "            if stall_count < len(bait_prompts):\n",
        "                bait_reply = bait_prompts[stall_count]\n",
        "                print(f\"洟 Bot: {bait_reply}\")\n",
        "                chat_log.append(f\"Bot: {bait_reply}\")\n",
        "                stall_count += 1\n",
        "            else:\n",
        "                print(\"洟 Bot: 泝 Scam conversation logged and flagged for security. Ending session.\")\n",
        "                log_scam_report(user_data, chat_log)\n",
        "                break\n",
        "            continue\n",
        "\n",
        "        user_id = user_data['user_id']\n",
        "        name = user_data['name']\n",
        "        recent_txns = get_user_transactions(user_id).head(3).to_dict('records')\n",
        "\n",
        "        context_prompt = (\n",
        "            f\"You are a banking assistant for SecureBank. The user is {name} with User ID: {user_id}. \"\n",
        "            f\"Their bank account is {user_data['bank_account']}, and crypto wallet is {user_data['crypto_wallet']}. \"\n",
        "            f\"Their credit score is {user_data['credit_score']} and balance is ${user_data['balance']:.2f}. \"\n",
        "            f\"Recent transactions: {recent_txns}.\\n\\n\"\n",
        "            f\"User said: '{user_input}'. Respond professionally and helpfully.\"\n",
        "        )\n",
        "\n",
        "        bot_reply = get_gpt_reply(context_prompt)\n",
        "        print(\"洟 Bot:\", bot_reply)\n",
        "        chat_log.append(f\"Bot: {bot_reply}\")\n",
        "\n",
        "start_chatbot()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install facenet-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9Bd4G3WMsZRv",
        "outputId": "35cae7ce-ff80-4b02-921f-99dc1be5476c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting facenet-pytorch\n",
            "  Downloading facenet_pytorch-2.6.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy<2.0.0,>=1.24.0 (from facenet-pytorch)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow<10.3.0,>=10.2.0 (from facenet-pytorch)\n",
            "  Downloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (2.32.3)\n",
            "Collecting torch<2.3.0,>=2.2.0 (from facenet-pytorch)\n",
            "  Downloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Collecting torchvision<0.18.0,>=0.17.0 (from facenet-pytorch)\n",
            "  Downloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from facenet-pytorch) (4.67.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.0.0->facenet-pytorch) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (4.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<2.3.0,>=2.2.0->facenet-pytorch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.2.0 (from torch<2.3.0,>=2.2.0->facenet-pytorch)\n",
            "  Downloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch<2.3.0,>=2.2.0->facenet-pytorch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<2.3.0,>=2.2.0->facenet-pytorch) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch<2.3.0,>=2.2.0->facenet-pytorch) (1.3.0)\n",
            "Downloading facenet_pytorch-2.6.0-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.2.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.2.2-cp311-cp311-manylinux1_x86_64.whl (755.6 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m68.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.17.2-cp311-cp311-manylinux1_x86_64.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤笏≫煤\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, Pillow, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, facenet-pytorch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.2.0\n",
            "    Uninstalling triton-3.2.0:\n",
            "      Successfully uninstalled triton-3.2.0\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.6.0+cu124\n",
            "    Uninstalling torch-2.6.0+cu124:\n",
            "      Successfully uninstalled torch-2.6.0+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.21.0+cu124\n",
            "    Uninstalling torchvision-0.21.0+cu124:\n",
            "      Successfully uninstalled torchvision-0.21.0+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-10.2.0 facenet-pytorch-2.6.0 numpy-1.26.4 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvtx-cu12-12.1.105 torch-2.2.2 torchvision-0.17.2 triton-2.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "nvidia"
                ]
              },
              "id": "62b5edd5ee464787bf2b17ffab26f7b1"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXhnuDKgYzE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a303c93-e6ac-42c8-ead7-747c4c286817"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-04-17 07:06:11 - Directory /root/.deepface has been created\n",
            "25-04-17 07:06:11 - Directory /root/.deepface/weights has been created\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels.h5\n",
            "91884032/91884032 [==============================] - 3s 0us/step\n",
            "沐 Document Verification: 笨 Document appears valid.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Action: emotion:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-04-17 07:06:37 - facial_expression_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
            "To: /root/.deepface/weights/facial_expression_model_weights.h5\n",
            "\n",
            "100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 5.98M/5.98M [00:00<00:00, 153MB/s]\n",
            "Action: age:  33%|笆遺毎笆遺鮪      | 1/3 [00:01<00:02,  1.13s/it]    "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-04-17 07:06:40 - age_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/age_model_weights.h5\n",
            "To: /root/.deepface/weights/age_model_weights.h5\n",
            "\n",
            "  0%|          | 0.00/539M [00:00<?, ?B/s]\u001b[A\n",
            "  2%|笆         | 11.0M/539M [00:00<00:06, 87.6MB/s]\u001b[A\n",
            "  4%|笆         | 21.5M/539M [00:00<00:05, 93.9MB/s]\u001b[A\n",
            "  6%|笆         | 32.0M/539M [00:00<00:05, 94.8MB/s]\u001b[A\n",
            "  8%|笆         | 42.5M/539M [00:00<00:05, 83.0MB/s]\u001b[A\n",
            " 10%|笆         | 53.0M/539M [00:00<00:05, 88.5MB/s]\u001b[A\n",
            " 12%|笆遺柾        | 63.4M/539M [00:00<00:05, 88.9MB/s]\u001b[A\n",
            " 14%|笆遺鮪        | 73.9M/539M [00:00<00:05, 84.9MB/s]\u001b[A\n",
            " 16%|笆遺膜        | 84.4M/539M [00:00<00:05, 84.3MB/s]\u001b[A\n",
            " 18%|笆遺槙        | 94.9M/539M [00:01<00:05, 87.9MB/s]\u001b[A\n",
            " 20%|笆遺哩        | 105M/539M [00:01<00:04, 88.0MB/s] \u001b[A\n",
            " 22%|笆遺毎笆       | 116M/539M [00:01<00:04, 87.4MB/s]\u001b[A\n",
            " 23%|笆遺毎笆       | 126M/539M [00:01<00:04, 91.4MB/s]\u001b[A\n",
            " 25%|笆遺毎笆       | 137M/539M [00:01<00:04, 92.5MB/s]\u001b[A\n",
            " 27%|笆遺毎笆       | 147M/539M [00:01<00:04, 93.9MB/s]\u001b[A\n",
            " 29%|笆遺毎笆       | 158M/539M [00:01<00:04, 92.9MB/s]\u001b[A\n",
            " 31%|笆遺毎笆       | 168M/539M [00:01<00:03, 92.8MB/s]\u001b[A\n",
            " 33%|笆遺毎笆遺鮪      | 179M/539M [00:01<00:03, 94.3MB/s]\u001b[A\n",
            " 35%|笆遺毎笆遺膜      | 189M/539M [00:02<00:03, 91.5MB/s]\u001b[A\n",
            " 37%|笆遺毎笆遺幕      | 199M/539M [00:02<00:04, 76.4MB/s]\u001b[A\n",
            " 38%|笆遺毎笆遺槙      | 207M/539M [00:02<00:04, 75.7MB/s]\u001b[A\n",
            " 40%|笆遺毎笆遺哩      | 215M/539M [00:02<00:04, 76.1MB/s]\u001b[A\n",
            " 42%|笆遺毎笆遺毎笆     | 224M/539M [00:02<00:03, 79.3MB/s]\u001b[A\n",
            " 43%|笆遺毎笆遺毎笆     | 232M/539M [00:02<00:04, 76.2MB/s]\u001b[A\n",
            " 45%|笆遺毎笆遺毎笆     | 242M/539M [00:02<00:03, 79.6MB/s]\u001b[A\n",
            " 47%|笆遺毎笆遺毎笆     | 252M/539M [00:02<00:03, 85.2MB/s]\u001b[A\n",
            " 49%|笆遺毎笆遺毎笆     | 263M/539M [00:03<00:03, 88.5MB/s]\u001b[A\n",
            " 51%|笆遺毎笆遺毎笆     | 273M/539M [00:03<00:03, 83.9MB/s]\u001b[A\n",
            " 53%|笆遺毎笆遺毎笆遺鮪    | 284M/539M [00:03<00:03, 83.3MB/s]\u001b[A\n",
            " 55%|笆遺毎笆遺毎笆遺枕    | 294M/539M [00:03<00:02, 86.6MB/s]\u001b[A\n",
            " 57%|笆遺毎笆遺毎笆遺幕    | 305M/539M [00:03<00:02, 89.6MB/s]\u001b[A\n",
            " 58%|笆遺毎笆遺毎笆遺槙    | 315M/539M [00:03<00:02, 89.8MB/s]\u001b[A\n",
            " 60%|笆遺毎笆遺毎笆遺毎    | 326M/539M [00:03<00:02, 88.5MB/s]\u001b[A\n",
            " 62%|笆遺毎笆遺毎笆遺毎笆   | 336M/539M [00:03<00:02, 92.0MB/s]\u001b[A\n",
            " 64%|笆遺毎笆遺毎笆遺毎笆   | 347M/539M [00:03<00:02, 94.3MB/s]\u001b[A\n",
            " 66%|笆遺毎笆遺毎笆遺毎笆   | 357M/539M [00:04<00:01, 93.2MB/s]\u001b[A\n",
            " 68%|笆遺毎笆遺毎笆遺毎笆   | 368M/539M [00:04<00:01, 92.8MB/s]\u001b[A\n",
            " 70%|笆遺毎笆遺毎笆遺毎笆   | 378M/539M [00:04<00:01, 95.7MB/s]\u001b[A\n",
            " 72%|笆遺毎笆遺毎笆遺毎笆遺柾  | 388M/539M [00:04<00:01, 96.6MB/s]\u001b[A\n",
            " 74%|笆遺毎笆遺毎笆遺毎笆遺枕  | 399M/539M [00:04<00:01, 92.3MB/s]\u001b[A\n",
            " 76%|笆遺毎笆遺毎笆遺毎笆遺膜  | 409M/539M [00:04<00:01, 90.9MB/s]\u001b[A\n",
            " 78%|笆遺毎笆遺毎笆遺毎笆遺槙  | 420M/539M [00:04<00:01, 93.5MB/s]\u001b[A\n",
            " 80%|笆遺毎笆遺毎笆遺毎笆遺哩  | 430M/539M [00:04<00:01, 95.6MB/s]\u001b[A\n",
            " 82%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 441M/539M [00:04<00:01, 97.6MB/s]\u001b[A\n",
            " 84%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 451M/539M [00:05<00:00, 98.0MB/s]\u001b[A\n",
            " 86%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 462M/539M [00:05<00:00, 99.1MB/s]\u001b[A\n",
            " 88%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 472M/539M [00:05<00:00, 97.8MB/s]\u001b[A\n",
            " 90%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 483M/539M [00:05<00:00, 92.7MB/s]\u001b[A\n",
            " 92%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺柾| 493M/539M [00:05<00:00, 94.4MB/s]\u001b[A\n",
            " 93%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺鮪| 503M/539M [00:06<00:00, 38.2MB/s]\u001b[A\n",
            " 95%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺枕| 511M/539M [00:06<00:00, 33.5MB/s]\u001b[A\n",
            " 97%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺幕| 525M/539M [00:06<00:00, 46.6MB/s]\u001b[A\n",
            "100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 539M/539M [00:06<00:00, 80.3MB/s]\n",
            "Action: gender:  67%|笆遺毎笆遺毎笆遺毎笆   | 2/3 [00:13<00:07,  7.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-04-17 07:06:52 - gender_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/gender_model_weights.h5\n",
            "To: /root/.deepface/weights/gender_model_weights.h5\n",
            "\n",
            "  0%|          | 0.00/537M [00:00<?, ?B/s]\u001b[A\n",
            "  2%|笆         | 11.0M/537M [00:00<00:05, 91.0MB/s]\u001b[A\n",
            "  4%|笆         | 21.5M/537M [00:00<00:06, 74.8MB/s]\u001b[A\n",
            "  6%|笆         | 32.0M/537M [00:00<00:06, 78.8MB/s]\u001b[A\n",
            "  8%|笆         | 42.5M/537M [00:00<00:05, 86.2MB/s]\u001b[A\n",
            " 10%|笆         | 53.0M/537M [00:00<00:05, 81.4MB/s]\u001b[A\n",
            " 12%|笆遺柾        | 63.4M/537M [00:00<00:05, 79.6MB/s]\u001b[A\n",
            " 14%|笆遺枕        | 73.9M/537M [00:00<00:06, 76.2MB/s]\u001b[A\n",
            " 16%|笆遺膜        | 84.4M/537M [00:01<00:05, 81.4MB/s]\u001b[A\n",
            " 18%|笆遺槙        | 94.9M/537M [00:01<00:05, 81.4MB/s]\u001b[A\n",
            " 20%|笆遺哩        | 105M/537M [00:01<00:05, 83.6MB/s] \u001b[A\n",
            " 22%|笆遺毎笆       | 116M/537M [00:01<00:04, 87.0MB/s]\u001b[A\n",
            " 24%|笆遺毎笆       | 126M/537M [00:01<00:04, 89.6MB/s]\u001b[A\n",
            " 25%|笆遺毎笆       | 137M/537M [00:01<00:04, 92.0MB/s]\u001b[A\n",
            " 27%|笆遺毎笆       | 147M/537M [00:01<00:04, 92.6MB/s]\u001b[A\n",
            " 29%|笆遺毎笆       | 158M/537M [00:01<00:04, 92.0MB/s]\u001b[A\n",
            " 31%|笆遺毎笆       | 167M/537M [00:02<00:04, 80.8MB/s]\u001b[A\n",
            " 33%|笆遺毎笆遺鮪      | 176M/537M [00:02<00:04, 78.8MB/s]\u001b[A\n",
            " 34%|笆遺毎笆遺枕      | 184M/537M [00:02<00:04, 78.8MB/s]\u001b[A\n",
            " 36%|笆遺毎笆遺膜      | 192M/537M [00:02<00:04, 79.8MB/s]\u001b[A\n",
            " 38%|笆遺毎笆遺槙      | 204M/537M [00:02<00:03, 90.8MB/s]\u001b[A\n",
            " 40%|笆遺毎笆遺哩      | 214M/537M [00:02<00:03, 90.6MB/s]\u001b[A\n",
            " 42%|笆遺毎笆遺毎笆     | 225M/537M [00:02<00:03, 97.4MB/s]\u001b[A\n",
            " 44%|笆遺毎笆遺毎笆     | 235M/537M [00:02<00:03, 97.2MB/s]\u001b[A\n",
            " 46%|笆遺毎笆遺毎笆     | 245M/537M [00:02<00:03, 93.6MB/s]\u001b[A\n",
            " 47%|笆遺毎笆遺毎笆     | 255M/537M [00:02<00:03, 88.8MB/s]\u001b[A\n",
            " 49%|笆遺毎笆遺毎笆     | 264M/537M [00:03<00:03, 86.8MB/s]\u001b[A\n",
            " 51%|笆遺毎笆遺毎笆     | 273M/537M [00:03<00:03, 83.3MB/s]\u001b[A\n",
            " 53%|笆遺毎笆遺毎笆遺鮪    | 284M/537M [00:03<00:02, 87.6MB/s]\u001b[A\n",
            " 55%|笆遺毎笆遺毎笆遺枕    | 294M/537M [00:03<00:02, 90.6MB/s]\u001b[A\n",
            " 57%|笆遺毎笆遺毎笆遺幕    | 305M/537M [00:03<00:02, 79.1MB/s]\u001b[A\n",
            " 59%|笆遺毎笆遺毎笆遺槙    | 315M/537M [00:03<00:02, 80.4MB/s]\u001b[A\n",
            " 61%|笆遺毎笆遺毎笆遺毎    | 326M/537M [00:03<00:02, 79.9MB/s]\u001b[A\n",
            " 63%|笆遺毎笆遺毎笆遺毎笆   | 336M/537M [00:03<00:02, 84.0MB/s]\u001b[A\n",
            " 65%|笆遺毎笆遺毎笆遺毎笆   | 347M/537M [00:04<00:02, 86.0MB/s]\u001b[A\n",
            " 66%|笆遺毎笆遺毎笆遺毎笆   | 357M/537M [00:04<00:02, 89.5MB/s]\u001b[A\n",
            " 68%|笆遺毎笆遺毎笆遺毎笆   | 366M/537M [00:05<00:05, 29.9MB/s]\u001b[A\n",
            " 70%|笆遺毎笆遺毎笆遺毎笆   | 378M/537M [00:05<00:04, 39.3MB/s]\u001b[A\n",
            " 72%|笆遺毎笆遺毎笆遺毎笆遺柾  | 388M/537M [00:05<00:03, 43.9MB/s]\u001b[A\n",
            " 74%|笆遺毎笆遺毎笆遺毎笆遺枕  | 399M/537M [00:05<00:02, 48.2MB/s]\u001b[A\n",
            " 76%|笆遺毎笆遺毎笆遺毎笆遺膜  | 409M/537M [00:05<00:02, 55.5MB/s]\u001b[A\n",
            " 78%|笆遺毎笆遺毎笆遺毎笆遺槙  | 420M/537M [00:05<00:01, 63.6MB/s]\u001b[A\n",
            " 80%|笆遺毎笆遺毎笆遺毎笆遺毎  | 430M/537M [00:05<00:01, 69.7MB/s]\u001b[A\n",
            " 82%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 441M/537M [00:05<00:01, 74.3MB/s]\u001b[A\n",
            " 84%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 451M/537M [00:06<00:01, 78.5MB/s]\u001b[A\n",
            " 86%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 462M/537M [00:06<00:00, 80.4MB/s]\u001b[A\n",
            " 88%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 472M/537M [00:06<00:00, 80.7MB/s]\u001b[A\n",
            " 90%|笆遺毎笆遺毎笆遺毎笆遺毎笆 | 483M/537M [00:06<00:00, 84.4MB/s]\u001b[A\n",
            " 92%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺柾| 493M/537M [00:06<00:00, 88.9MB/s]\u001b[A\n",
            " 94%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺枕| 504M/537M [00:06<00:00, 91.8MB/s]\u001b[A\n",
            " 96%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺膜| 514M/537M [00:06<00:00, 94.2MB/s]\u001b[A\n",
            " 98%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺槙| 525M/537M [00:06<00:00, 87.2MB/s]\u001b[A\n",
            "100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 537M/537M [00:07<00:00, 76.7MB/s]\n",
            "Action: gender: 100%|笆遺毎笆遺毎笆遺毎笆遺毎笆遺毎| 3/3 [00:24<00:00,  8.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "洫 Deepfake Analysis: {'DeepFace Analysis': [{'emotion': {'angry': 29.814082384109497, 'disgust': 3.893410333716263e-10, 'fear': 0.03988707030657679, 'happy': 4.2577011072353343e-05, 'sad': 1.0136501863598824, 'surprise': 8.351161540076646e-06, 'neutral': 69.13232803344727}, 'dominant_emotion': 'neutral', 'region': {'x': 525, 'y': 240, 'w': 268, 'h': 268, 'left_eye': (707, 346), 'right_eye': (594, 350)}, 'face_confidence': 0.92, 'age': 30, 'gender': {'Woman': 6.645332746302302e-05, 'Man': 99.99992847442627}, 'dominant_gender': 'Man'}], 'XceptionNet Deepfake Score': 0.09690051525831223}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import cv2\n",
        "import pytesseract\n",
        "import spacy\n",
        "import exifread\n",
        "from skimage import feature\n",
        "from skimage.io import imread\n",
        "from skimage.restoration import estimate_sigma\n",
        "from skimage.filters import gaussian\n",
        "from skimage.color import rgb2gray\n",
        "from deepface import DeepFace\n",
        "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from facenet_pytorch import MTCNN\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "nlp_ner = spacy.load(\"en_core_web_sm\")\n",
        "xception_model = Xception(weights=\"imagenet\", include_top=True)\n",
        "mtcnn = MTCNN()\n",
        "\n",
        "financial_data = pd.read_csv(\"mixed_transactions.csv\")\n",
        "scam_logs = []\n",
        "fraud_logs = []\n",
        "\n",
        "def extract_entities(text):\n",
        "    \"\"\"Extract sensitive entities from OCR text using spaCy NER.\"\"\"\n",
        "    doc = nlp_ner(text)\n",
        "    entities = {ent.label_: ent.text for ent in doc.ents if ent.label_ in [\"MONEY\", \"PERSON\", \"ORG\", \"CARDINAL\"]}\n",
        "    return entities\n",
        "\n",
        "def document_metadata_analysis(image_path):\n",
        "    \"\"\"Extract EXIF metadata from image to detect signs of editing.\"\"\"\n",
        "    try:\n",
        "        with open(image_path, 'rb') as img_file:\n",
        "            tags = exifread.process_file(img_file)\n",
        "        return tags\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "def noise_analysis(image_path):\n",
        "    \"\"\"Analyze noise using Bayesian-style filtering to flag inconsistencies.\"\"\"\n",
        "    image = imread(image_path)\n",
        "    grayscale = rgb2gray(image)\n",
        "    sigma_est = estimate_sigma(grayscale, channel_axis=None, average_sigmas=True)\n",
        "    smoothed = gaussian(grayscale, sigma=1)\n",
        "    noise_level = np.mean(np.abs(grayscale - smoothed))\n",
        "    return sigma_est, noise_level\n",
        "\n",
        "def texture_analysis(image_path):\n",
        "    \"\"\"Analyze texture using LBP and edge features to detect manipulation.\"\"\"\n",
        "    image = rgb2gray(imread(image_path))\n",
        "    lbp = feature.local_binary_pattern(image, P=24, R=3, method='uniform')\n",
        "    lbp_hist, _ = np.histogram(lbp.ravel(), bins=np.arange(0, 27), density=True)\n",
        "    edge_density = np.sum(feature.canny(image, sigma=1.5)) / image.size\n",
        "    return edge_density, np.var(lbp_hist)\n",
        "\n",
        "def cross_reference_financial_entities(entities):\n",
        "    \"\"\"Cross-check extracted entities with financial records for signs of fraud.\"\"\"\n",
        "    matches = []\n",
        "    for label, entity in entities.items():\n",
        "        if label in [\"MONEY\", \"CARDINAL\"] and entity in financial_data[\"amount\"].astype(str).values:\n",
        "            matches.append(entity)\n",
        "        elif label in [\"PERSON\", \"ORG\"] and entity in financial_data[\"user_id\"].astype(str).values:\n",
        "            matches.append(entity)\n",
        "    return matches\n",
        "\n",
        "def fake_document_detection(image_path):\n",
        "    \"\"\"Detect fake documents using OCR, EXIF, noise, texture and entity analysis.\"\"\"\n",
        "    try:\n",
        "        text = pytesseract.image_to_string(cv2.imread(image_path))\n",
        "        entities = extract_entities(text)\n",
        "        metadata = document_metadata_analysis(image_path)\n",
        "        sigma_est, noise_level = noise_analysis(image_path)\n",
        "        edge_density, lbp_variance = texture_analysis(image_path)\n",
        "        matched_entities = cross_reference_financial_entities(entities)\n",
        "\n",
        "        if matched_entities:\n",
        "            scam_logs.append({\"document\": image_path, \"entities\": matched_entities})\n",
        "            return f\"笞ｸ ALERT: Fake document suspected. Matched entities: {matched_entities}\"\n",
        "\n",
        "        if noise_level > 0.03 or sigma_est > 0.02:\n",
        "            return \"笞ｸ High noise anomaly detected. Possible forgery.\"\n",
        "\n",
        "        if edge_density > 0.1 or lbp_variance > 0.02:\n",
        "            return \"笞ｸ Suspicious texture pattern detected. Possible document manipulation.\"\n",
        "\n",
        "        return \"笨 Document appears valid.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error in document analysis: {str(e)}\"\n",
        "\n",
        "def deepfake_detection(image_path):\n",
        "    \"\"\"Detect deepfakes using DeepFace + XceptionNet.\"\"\"\n",
        "    try:\n",
        "        deepface_result = DeepFace.analyze(image_path, actions=['emotion', 'age', 'gender'], enforce_detection=False)\n",
        "\n",
        "        img = image.load_img(image_path, target_size=(299, 299))\n",
        "        img_array = image.img_to_array(img)\n",
        "        img_array = np.expand_dims(img_array, axis=0)\n",
        "        img_array = preprocess_input(img_array)\n",
        "        xception_pred = xception_model.predict(img_array)\n",
        "        deepfake_score = np.max(xception_pred)\n",
        "\n",
        "        fraud_logs.append({\"image\": image_path, \"deepfake_score\": float(deepfake_score)})\n",
        "        return {\n",
        "            \"DeepFace Analysis\": deepface_result,\n",
        "            \"XceptionNet Deepfake Score\": float(deepfake_score)\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\"error\": str(e)}\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_image = \"/content/mukesh1.jpg\"\n",
        "\n",
        "    print(\"沐 Document Verification:\", fake_document_detection(test_image))\n",
        "    print(\"洫 Deepfake Analysis:\", deepfake_detection(test_image))\n",
        "\n",
        "    pd.DataFrame(scam_logs).to_csv(\"scam_logs.csv\", index=False)\n",
        "    pd.DataFrame(fraud_logs).to_csv(\"fraud_logs.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mzNXyGiYzAB",
        "outputId": "f65ed93c-1402-485b-8da7-db906086fb8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "96/96 [==============================] - 0s 1ms/step\n",
            "\n",
            "沐 USER AUTHENTICATION\n",
            "Enter your user ID: 59b03ad2-36cb-4fad-8f00-a23df48c9c98\n",
            "\n",
            "沒 Enter Transaction Details\n",
            "Transaction Type (e.g., transfer, deposit, withdrawal): withdrawal\n",
            "Amount: 150000\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "\n",
            "泄ｵｸ Classification Result: FRAUDULENT\n",
            "竊 Isolation Forest: 1 | Autoencoder: 1\n",
            "竊 Risk Score: 100.00/100\n",
            "竊 Fraud Alerts for this user: 1\n",
            "沒ｧ Alert email sent.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras import regularizers\n",
        "import requests\n",
        "\n",
        "\n",
        "api_key = '61b74a9cebf04b548659147adb6eb33b'\n",
        "api_secret = '1d8e068d7b172e50d4a929a1bbb57283'\n",
        "sender_email = 'sakshiikediaa@gmail.com'\n",
        "receiver_email = 'mukeshjk104@gmail.com'\n",
        "\n",
        "\n",
        "users_df = pd.read_csv(\"mixed_users.csv\")\n",
        "transactions_df = pd.read_csv(\"mixed_transactions.csv\")\n",
        "\n",
        "categorical_features = ['transaction_type']\n",
        "numerical_features = ['amount']\n",
        "\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoded_cat = encoder.fit_transform(transactions_df[categorical_features])\n",
        "scaler = StandardScaler()\n",
        "scaled_num = scaler.fit_transform(transactions_df[numerical_features])\n",
        "\n",
        "X = np.hstack([scaled_num, encoded_cat])\n",
        "y = transactions_df['fraudulent'].values\n",
        "\n",
        "isoforest = IsolationForest(n_estimators=100, contamination=0.2, random_state=42)\n",
        "isoforest.fit(X)\n",
        "\n",
        "input_dim = X.shape[1]\n",
        "encoding_dim = 8\n",
        "\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(32, activation=\"relu\", activity_regularizer=regularizers.l1(1e-5))(input_layer)\n",
        "encoded = Dense(encoding_dim, activation=\"relu\")(encoded)\n",
        "decoded = Dense(32, activation='relu')(encoded)\n",
        "decoded = Dense(input_dim, activation='linear')(decoded)\n",
        "\n",
        "autoencoder = Model(input_layer, decoded)\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.fit(X, X, epochs=30, batch_size=64, shuffle=True, validation_split=0.1, verbose=0)\n",
        "\n",
        "threshold = np.percentile(np.mean((X - autoencoder.predict(X)) ** 2, axis=1), 80)\n",
        "\n",
        "fraud_log = {}\n",
        "\n",
        "def send_alert_email(user, amount, txn_type, score):\n",
        "    data = {\n",
        "        'Messages': [{\n",
        "            \"From\": {\"Email\": sender_email, \"Name\": \"Financial Honeypot\"},\n",
        "            \"To\": [{\"Email\": receiver_email, \"Name\": \"Security Team\"}],\n",
        "            \"Subject\": \"泅ｨ Suspicious Transaction Detected\",\n",
        "            \"TextPart\": f\"\"\"\n",
        "High-risk transaction detected!\n",
        "\n",
        "User: {user['name']}\n",
        "Credit Score: {user['credit_score']}\n",
        "Transaction Type: {txn_type}\n",
        "Amount: ${amount}\n",
        "Risk Score: {score:.2f}/100\n",
        "\n",
        "Please investigate immediately.\n",
        "\"\"\"\n",
        "        }]\n",
        "    }\n",
        "\n",
        "    response = requests.post(\n",
        "        \"https://api.mailjet.com/v3.1/send\",\n",
        "        auth=(api_key, api_secret),\n",
        "        json=data\n",
        "    )\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        print(\"沒ｧ Alert email sent.\")\n",
        "    else:\n",
        "        print(f\"笶 Email failed. Status Code: {response.status_code}\")\n",
        "        print(\"沐 Response JSON:\", response.json())\n",
        "\n",
        "def classify_transaction():\n",
        "    print(\"\\n沐 USER AUTHENTICATION\")\n",
        "    user_id = input(\"Enter your user ID: \").strip()\n",
        "    user = users_df[users_df['user_id'] == user_id]\n",
        "\n",
        "    if user.empty:\n",
        "        print(\"笶 Invalid user ID.\")\n",
        "        return\n",
        "\n",
        "    user = user.iloc[0]\n",
        "\n",
        "    print(\"\\n沒 Enter Transaction Details\")\n",
        "    txn_type = input(\"Transaction Type (e.g., transfer, deposit, withdrawal): \").strip().lower()\n",
        "    try:\n",
        "        amount = float(input(\"Amount: \"))\n",
        "    except ValueError:\n",
        "        print(\"笶 Invalid amount.\")\n",
        "        return\n",
        "\n",
        "    user_df = pd.DataFrame([[amount, txn_type]], columns=['amount', 'transaction_type'])\n",
        "    try:\n",
        "        user_cat = encoder.transform(user_df[categorical_features])\n",
        "    except Exception as e:\n",
        "        print(\"笶 Invalid transaction type.\")\n",
        "        return\n",
        "\n",
        "    user_num = scaler.transform(user_df[numerical_features])\n",
        "    user_X = np.hstack([user_num, user_cat])\n",
        "\n",
        "    iso_pred = isoforest.predict(user_X)\n",
        "    iso_anomaly = 1 if iso_pred[0] == -1 else 0\n",
        "\n",
        "    recon = autoencoder.predict(user_X)\n",
        "    recon_error = np.mean((user_X - recon) ** 2)\n",
        "    auto_anomaly = 1 if recon_error > threshold else 0\n",
        "\n",
        "    risk_score = min((0.5 * iso_anomaly + 0.5 * auto_anomaly + 0.05 * fraud_log.get(user_id, 0)) * 100, 100)\n",
        "    prediction = \"FRAUDULENT\" if risk_score >= 50 else \"NORMAL\"\n",
        "\n",
        "    if prediction == \"FRAUDULENT\":\n",
        "        fraud_log[user_id] = fraud_log.get(user_id, 0) + 1\n",
        "    else:\n",
        "        fraud_log.setdefault(user_id, 0)\n",
        "\n",
        "    print(\"\\n泄ｵｸ Classification Result:\", prediction)\n",
        "    print(f\"竊 Isolation Forest: {iso_anomaly} | Autoencoder: {auto_anomaly}\")\n",
        "    print(f\"竊 Risk Score: {risk_score:.2f}/100\")\n",
        "    print(f\"竊 Fraud Alerts for this user: {fraud_log[user_id]}\")\n",
        "\n",
        "    if risk_score >= 80:\n",
        "        send_alert_email(user, amount, txn_type, risk_score)\n",
        "\n",
        "classify_transaction()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}